{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51df98f4-0dcb-4a5a-a8b8-9ad05613edbc",
   "metadata": {},
   "source": [
    "## VectorSotre Chroma DB  with Langchain Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e67cfc1-2e1b-49b8-99a5-ffcecf6dbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b837b136-99eb-4d92-9a3a-049e18f2c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory Constant\n",
    "CACHE_DATASET_DIR = Path('cache_dir')\n",
    "CHROMA_DB_DIR = Path('Knowledge_space')\n",
    "if not CHROMA_DB_DIR.is_dir():\n",
    "    CHROMA_DB_DIR.mkdir(parents=True)\n",
    "if not CACHE_DATASET_DIR.is_dir():\n",
    "    CACHE_DATASET_DIR.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b946ba-e498-4b51-ae40-683c69bea365",
   "metadata": {},
   "source": [
    "### Sentence Transformer Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24be84ef-acc1-438e-8256-5ea7f41882c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer \\\n",
    "import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1491e07-4fc2-4967-b7dc-a72a0b8f0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aba59b-0550-4ae8-8028-b63e8bdc8fc5",
   "metadata": {},
   "source": [
    "### Text Content Extraction from PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd50958-f774-4a89-b3ee-a56b7aa0b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097a628b-cb11-4512-93d8-ff537dbe514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='be able to reproduce, animals must solve a continuous stream of problems during theirlives, e.g., ﬁnding food, avoiding predators, mating, and parenting. This suggests that\\nhuman intelligence primarily evolved for solving everyday problems related to survival\\nin the different habitats of Homo sapiens .\\nArtiﬁcial Intelligence started as an attempt to reproduce parts of human intelligence\\nin machines and, just like the notion of human intelligence, it is associated with a\\ncertain vagueness regarding its deﬁnition, targeted problems, performance measures,\\nand relations to neighboring research ﬁelds.\\nRecently, AI research has been quite successful at producing systems that are gen-\\neral in the sense that they can translate between many languages, play many games,\\nmanipulate many objects, predict many video frames, write many texts, generate many\\nimages, and diagnose many diseases.\\nStill, many of the basic challenges of AGI remain unsolved. In fact, we do not yet', metadata={'source': './tmp/tmp.pdf', 'page': 5})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./tmp/tmp.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
    "texts = text_spliter.split_documents(pages)\n",
    "texts[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5174de-18b3-45af-a04b-61997c3e7bcf",
   "metadata": {},
   "source": [
    "### Creating Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd9a3ed-95e3-439c-a14e-056bb8c670da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'WindowsPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[19], line 1\u001b[0m\n    db = Chroma.from_documents(documents=texts,\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:778\u001b[0m in \u001b[0;35mfrom_documents\u001b[0m\n    return cls.from_texts(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:742\u001b[0m in \u001b[0;35mfrom_texts\u001b[0m\n    chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:297\u001b[0m in \u001b[0;35madd_texts\u001b[0m\n    self._collection.upsert(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:306\u001b[0m in \u001b[0;35mupsert\u001b[0m\n    self._client._upsert(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\api\\local.py:304\u001b[0m in \u001b[0;35m_upsert\u001b[0m\n    self._add(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\api\\local.py:248\u001b[0m in \u001b[0;35m_add\u001b[0m\n    self._db.add_incremental(collection_id, added_uuids, embeddings)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\db\\clickhouse.py:612\u001b[0m in \u001b[0;35madd_incremental\u001b[0m\n    index = self._index(collection_uuid)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\db\\clickhouse.py:98\u001b[0m in \u001b[0;35m_index\u001b[0m\n    index = Hnswlib(\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\chromadb\\db\\index\\hnswlib.py:92\u001b[1;36m in \u001b[1;35m__init__\u001b[1;36m\n\u001b[1;33m    self._save_folder = settings.persist_directory + \"/index\"\u001b[1;36m\n",
      "\u001b[1;31mTypeError\u001b[0m\u001b[1;31m:\u001b[0m unsupported operand type(s) for +: 'WindowsPath' and 'str'\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(documents=texts,\n",
    "                           embedding=embedding_function, \n",
    "                           persist_directory=CHROMA_DB_DIR.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fdc0721-8d17-4bf9-9b57-ec6a27d4c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Q Learning\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[1].page_content)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42f10503-60c5-49b2-97ad-648fd7c394a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_documents in module langchain_community.vectorstores.chroma:\n",
      "\n",
      "from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' method of abc.ABCMeta instance\n",
      "    Create a Chroma vectorstore from a list of documents.\n",
      "    \n",
      "    If a persist_directory is specified, the collection will be persisted there.\n",
      "    Otherwise, the data will be ephemeral in-memory.\n",
      "    \n",
      "    Args:\n",
      "        collection_name (str): Name of the collection to create.\n",
      "        persist_directory (Optional[str]): Directory to persist the collection.\n",
      "        ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      "        documents (List[Document]): List of documents to add to the vectorstore.\n",
      "        embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      "        client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      "        collection_metadata (Optional[Dict]): Collection configurations.\n",
      "                                              Defaults to None.\n",
      "    \n",
      "    Returns:\n",
      "        Chroma: Chroma vectorstore.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help( Chroma.from_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d915a51-fade-4130-b0a1-f2d473272832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/AritraRanjanChowdhury/GEN_AI/Assignment_PDF_Question_Answer/Knowledge_space'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHROMA_DB_DIR.resolve().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd91ba9-7239-4c6b-9b39-7f17f45ec4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
