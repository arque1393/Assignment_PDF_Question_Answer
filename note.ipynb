{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f542d208-4b12-4df5-a189-9bb6cbc51eb6",
   "metadata": {},
   "source": [
    "## PDF Query using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "445d6ce8-5f29-4980-b02f-ace68a11c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display as disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338be3b8-51fe-4d6a-b08a-650746d75541",
   "metadata": {},
   "source": [
    "### Loading PDF on langchain document loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0685802-352d-43cd-b62c-3f05a5d890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0d6205-2137-40ac-9d44-ced05e2eac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of page  = 380\n",
      "page_content length = 192\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./tmp/tmp.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f'no of page  = {len(pages)}')\n",
    "print(f'page_content length = {len(pages[0].page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9763368-025a-43ce-a16d-de8ba2827902",
   "metadata": {},
   "source": [
    "#### Data Chunks in smaller documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e211e25-45d7-4b00-8b6e-4e1079204ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='be able to reproduce, animals must solve a continuous stream of problems during theirlives, e.g., ﬁnding food, avoiding predators, mating, and parenting. This suggests that\\nhuman intelligence primarily evolved for solving everyday problems related to survival\\nin the different habitats of Homo sapiens .\\nArtiﬁcial Intelligence started as an attempt to reproduce parts of human intelligence\\nin machines and, just like the notion of human intelligence, it is associated with a\\ncertain vagueness regarding its deﬁnition, targeted problems, performance measures,\\nand relations to neighboring research ﬁelds.\\nRecently, AI research has been quite successful at producing systems that are gen-\\neral in the sense that they can translate between many languages, play many games,\\nmanipulate many objects, predict many video frames, write many texts, generate many\\nimages, and diagnose many diseases.\\nStill, many of the basic challenges of AGI remain unsolved. In fact, we do not yet', metadata={'source': './tmp/tmp.pdf', 'page': 5})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
    "texts = text_spliter.split_documents(pages)\n",
    "texts[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97ea73-59ac-4d18-a78a-7c555d3b8d30",
   "metadata": {},
   "source": [
    "##### Database Connection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d1b30-1416-4c9c-b4ee-0a237311e602",
   "metadata": {},
   "source": [
    "## Embedding with Chroma DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87746e66-9965-4152-b413-54803d999631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\llm\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import Chroma  \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.pdf import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import  OpenAI\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# from langchain.document_loaders import TextLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10542fd8-4bbd-4d6d-baed-e5d0b323808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='be able to reproduce, animals must solve a continuous stream of problems during theirlives, e.g., ﬁnding food, avoiding predators, mating, and parenting. This suggests that\\nhuman intelligence primarily evolved for solving everyday problems related to survival\\nin the different habitats of Homo sapiens .\\nArtiﬁcial Intelligence started as an attempt to reproduce parts of human intelligence\\nin machines and, just like the notion of human intelligence, it is associated with a\\ncertain vagueness regarding its deﬁnition, targeted problems, performance measures,\\nand relations to neighboring research ﬁelds.\\nRecently, AI research has been quite successful at producing systems that are gen-\\neral in the sense that they can translate between many languages, play many games,\\nmanipulate many objects, predict many video frames, write many texts, generate many\\nimages, and diagnose many diseases.\\nStill, many of the basic challenges of AGI remain unsolved. In fact, we do not yet', metadata={'source': './tmp/tmp.pdf', 'page': 5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./tmp/tmp.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
    "texts = text_spliter.split_documents(pages)\n",
    "texts[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061818e7-fc06-431d-8fa3-43db9b1924ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Knowledge_space')\n",
    "CACHE_DATASET = Path('cache_dir')\n",
    "DATABASE_DIR = Path('Knowledge_space')\n",
    "if not DATABASE_DIR.is_dir():\n",
    "    DATABASE_DIR.mkdir(parents=True)\n",
    "if not CACHE_DATASET.is_dir():\n",
    "    CACHE_DATASET.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdb7d9d-39b2-4bc9-98ba-5ada95f40a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", \n",
    "    cache_folder = CACHE_DATASET \n",
    ")\n",
    "# text_embedding_vector = embedding_model.encode([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb5422-b6c5-4045-bb59-c84ab19176d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_text = np.array([text.page_content for text in texts])\n",
    "exp_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8b166-de00-4372-aa6e-6749512ff008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549a9612-f974-40ed-95d8-f8dd525dbea8",
   "metadata": {},
   "source": [
    "### Creating Vector Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c24f342c-f6b4-4cdc-8962-f22652d69a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'SentenceTransformer' has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[9], line 1\u001b[0m\n    vector_db=Chroma.from_documents(documents=texts,\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:778\u001b[0m in \u001b[0;35mfrom_documents\u001b[0m\n    return cls.from_texts(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:742\u001b[0m in \u001b[0;35mfrom_texts\u001b[0m\n    chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:275\u001b[1;36m in \u001b[1;35madd_texts\u001b[1;36m\n\u001b[1;33m    embeddings = self._embedding_function.embed_documents(texts)\u001b[1;36m\n",
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m type object 'SentenceTransformer' has no attribute 'embed_documents'\n"
     ]
    }
   ],
   "source": [
    "vector_db=Chroma.from_documents(documents=texts,\n",
    "                               embedding = SentenceTransformer,\n",
    "                               persist_directory=DATABASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf78c9c0-4bbc-4fd5-9f63-df7ecf057820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "db_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00389ca2-bad1-4e60-a8ff-f785791d3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29387f-1f9d-4622-af32-60ae55274ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction,sentence]])\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "347dab73-a855-44eb-8aaf-39f54747a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfbadce8abc41e3be003d6c15ab5c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\llm\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--hkunlp--instructor-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[57], line 2\u001b[0m\n    model = INSTRUCTOR('hkunlp/instructor-base')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\SentenceTransformer.py:194\u001b[1;36m in \u001b[1;35m__init__\u001b[1;36m\n",
      "\u001b[1;31mTypeError\u001b[0m\u001b[1;31m:\u001b[0m INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-xl')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction,sentence]])\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca567e9f-4a6d-4e4a-88fe-b31481db1f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd262d4-e582-4846-951a-267e31c92fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8ec87-6745-4ddf-844f-3f719cdb3adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
