{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f542d208-4b12-4df5-a189-9bb6cbc51eb6",
   "metadata": {},
   "source": [
    "## PDF Query using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445d6ce8-5f29-4980-b02f-ace68a11c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display as disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338be3b8-51fe-4d6a-b08a-650746d75541",
   "metadata": {},
   "source": [
    "### Loading PDF on langchain document loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0685802-352d-43cd-b62c-3f05a5d890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0d6205-2137-40ac-9d44-ced05e2eac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of page  = 380\n",
      "page_content length = 192\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./tmp/tmp.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f'no of page  = {len(pages)}')\n",
    "print(f'page_content length = {len(pages[0].page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9763368-025a-43ce-a16d-de8ba2827902",
   "metadata": {},
   "source": [
    "#### Data Chunks in smaller documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e211e25-45d7-4b00-8b6e-4e1079204ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='be able to reproduce, animals must solve a continuous stream of problems during theirlives, e.g., ﬁnding food, avoiding predators, mating, and parenting. This suggests that\\nhuman intelligence primarily evolved for solving everyday problems related to survival\\nin the different habitats of Homo sapiens .\\nArtiﬁcial Intelligence started as an attempt to reproduce parts of human intelligence\\nin machines and, just like the notion of human intelligence, it is associated with a\\ncertain vagueness regarding its deﬁnition, targeted problems, performance measures,\\nand relations to neighboring research ﬁelds.\\nRecently, AI research has been quite successful at producing systems that are gen-\\neral in the sense that they can translate between many languages, play many games,\\nmanipulate many objects, predict many video frames, write many texts, generate many\\nimages, and diagnose many diseases.\\nStill, many of the basic challenges of AGI remain unsolved. In fact, we do not yet', metadata={'source': './tmp/tmp.pdf', 'page': 5})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
    "texts = text_spliter.split_documents(pages)\n",
    "texts[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97ea73-59ac-4d18-a78a-7c555d3b8d30",
   "metadata": {},
   "source": [
    "##### Database Connection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d1b30-1416-4c9c-b4ee-0a237311e602",
   "metadata": {},
   "source": [
    "## Embedding with Chroma DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87746e66-9965-4152-b413-54803d999631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import Chroma  \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.pdf import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import  OpenAI\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# from langchain.document_loaders import TextLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10542fd8-4bbd-4d6d-baed-e5d0b323808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='be able to reproduce, animals must solve a continuous stream of problems during theirlives, e.g., ﬁnding food, avoiding predators, mating, and parenting. This suggests that\\nhuman intelligence primarily evolved for solving everyday problems related to survival\\nin the different habitats of Homo sapiens .\\nArtiﬁcial Intelligence started as an attempt to reproduce parts of human intelligence\\nin machines and, just like the notion of human intelligence, it is associated with a\\ncertain vagueness regarding its deﬁnition, targeted problems, performance measures,\\nand relations to neighboring research ﬁelds.\\nRecently, AI research has been quite successful at producing systems that are gen-\\neral in the sense that they can translate between many languages, play many games,\\nmanipulate many objects, predict many video frames, write many texts, generate many\\nimages, and diagnose many diseases.\\nStill, many of the basic challenges of AGI remain unsolved. In fact, we do not yet', metadata={'source': './tmp/tmp.pdf', 'page': 5})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./tmp/tmp.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
    "texts = text_spliter.split_documents(pages)\n",
    "texts[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061818e7-fc06-431d-8fa3-43db9b1924ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Knowledge_space')\n",
    "CACHE_DATASET = Path('cache_dir')\n",
    "DATABASE_DIR = Path('Knowledge_space')\n",
    "if not DATABASE_DIR.is_dir():\n",
    "    DATABASE_DIR.mkdir(parents=True)\n",
    "if not CACHE_DATASET.is_dir():\n",
    "    CACHE_DATASET.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdb7d9d-39b2-4bc9-98ba-5ada95f40a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26951fdc63e148c997dfc5cd65bd08ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\AritraRanjanChowdhury\\GEN_AI\\Assignment_PDF_Question_Answer\\cache_dir\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9419ac5b356247c686d48113e9662c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb79e7886b453c835e0c86117af721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3834926ec1bb4f7c98ab039625239e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a001655af443a4bc109567413830ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2672bc1628a848b6a1d95bbc4c085e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51b6ae8db7d42e894d5de3cb9cabc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e725b5aff5645ed8d4e809a814c8737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958400f61ee24e079ffde0993253e9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb20860625848819598b763f143b684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23890783613e4ec683bb1513d11dc87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", \n",
    "    cache_folder = CACHE_DATASET.resolve().__str__()\n",
    ")\n",
    "\n",
    "# text_embedding_vector = embedding_model.encode([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffb5422-b6c5-4045-bb59-c84ab19176d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_text = np.array([text.page_content for text in texts])\n",
    "exp_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b8b166-de00-4372-aa6e-6749512ff008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer \\\n",
    "import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a9612-f974-40ed-95d8-f8dd525dbea8",
   "metadata": {},
   "source": [
    "### Creating Vector Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24f342c-f6b4-4cdc-8962-f22652d69a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_db=Chroma.from_documents(documents=texts,\n",
    "                               embedding = embedding_function,\n",
    "                               persist_directory= str(DATABASE_DIR.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf78c9c0-4bbc-4fd5-9f63-df7ecf057820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "db_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00389ca2-bad1-4e60-a8ff-f785791d3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29387f-1f9d-4622-af32-60ae55274ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction,sentence]])\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347dab73-a855-44eb-8aaf-39f54747a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-xl')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction,sentence]])\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca567e9f-4a6d-4e4a-88fe-b31481db1f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e5f29e3-6c4c-42c7-9b40-d371f69ff996",
   "metadata": {},
   "source": [
    "## Chroma DB Client and Lang Chain Chroma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e8ec87-6745-4ddf-844f-3f719cdb3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37bce092-44f4-4849-9264-ed044b6e6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = Path( 'VectorDB')\n",
    "user_1_db  = DATABASE_PATH/'user1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "109766e0-c7c8-4b48-9bbf-205279f35389",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=str(DATABASE_PATH.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab47bbe-be5a-4d95-ab8b-87a991e24e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5527bac3-2108-4af2-b8cc-cc13f2aad88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection = client.create_collection(name=\"Collection2\")\n",
    "collection = client.get_collection(name=\"Collection2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d91d220c-280b-49d0-b790-b168464181e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add', '_admin_client', '_count', '_create_system_if_not_exists', '_delete', '_get', '_get_identifier_from_settings', '_identifer_to_system', '_identifier', '_modify', '_peek', '_populate_data_from_system', '_query', '_server', '_system', '_update', '_upsert', '_validate_tenant_database', 'clear_system_cache', 'count_collections', 'create_collection', 'database', 'delete_collection', 'from_system', 'get_collection', 'get_or_create_collection', 'get_settings', 'get_version', 'heartbeat', 'list_collections', 'max_batch_size', 'reset', 'set_database', 'set_tenant', 'tenant']\n"
     ]
    }
   ],
   "source": [
    "print(dir(client))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "110eed84-5c00-45e5-a5b9-4f121b84a32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collection2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_collections()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a6b72fa-6162-4bb9-9224-b21c5a83a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('D:\\AritraRanjanChowdhury\\GEN_AI\\Assignment_PDF_Question_Answer\\APIService\\ChromaDB')\n",
    "client = chromadb.PersistentClient(path=str(path.resolve()))\n",
    "langchain_chroma = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"quantum_knowledge\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "chroma2 = Chroma(    \n",
    "   persist_directory=str(path.resolve()), embedding_function=embedding_function,collection_name=\"quantum_knowledge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61669d92-9c4d-4432-85cc-8b67c38a4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection('quantum_knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da2bbac6-ce7c-4dbd-98af-f0ebc542c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e6d06f-b16d-42a5-912b-b8792eafd1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_chroma.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2d3adf9-bd9f-4dbe-acac-bc9305a0fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_chroma = langchain_chroma.from_documents(texts, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b46dcb-ba06-4783-b363-bbb44386ec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_chroma.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcb4a652-10b2-4155-b59d-7c0c38163fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018CBF36AD10>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_chroma.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a19f0-03f0-4de4-bb45-791855eaddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_chroma.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd6065-b606-4816-a8da-f7a008156ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
